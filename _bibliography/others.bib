@article{PhysRev,
  abbr={NeurIPS OPT},
  title={Distributionally Robust Optimization via Diffusion Ambiguity Modeling},
  author={Jiaqi Wen^ and Yang, Jianyi},
  abstract={This paper studies Distributionally Robust Optimization (DRO), a fundamental framework for
enhancing the robustness and generalization of statistical learning and optimization. An effective
ambiguity set for DRO must involve distributions that remain consistent with the nominal distribu-
tion while being diverse enough to account for a variety of potential scenarios. Moreover, it should
lead to tractable DRO solutions. To this end, we propose a diffusion-based ambiguity set design
that captures various adversarial distributions beyond the nominal support space while maintain-
ing consistency with the nominal distribution. Building on this ambiguity modeling, we propose
Diffusion-based DRO (D-DRO), a tractable DRO algorithm that solves the inner maximization
over the parameterized diffusion model space. We formally establish the stationary convergence
performance of D-DRO and empirically demonstrate its superior Out-of-Distribution (OOD) gen-
eralization performance in a ML prediction task.},
  journal={17th Annual Workshop on Optimization for Machine Learning},
  year={2025},
  html={https://opt-ml.org/papers/2025/paper21.pdf},
  pdf={https://opt-ml.org/papers/2025/paper21.pdf},
  dimensions={false},
  selected={false}
}
